// Code generated by sqlc-connect (https://github.com/walterwanderley/sqlc-connect).

package main

import (
	"context"
	"database/sql"
	"errors"
	"flag"
	"fmt"
	"log/slog"
	"net/http"
	"os"
	"os/signal"
	"path/filepath"
	"runtime"
	"syscall"
	"time"

	"connectrpc.com/connect"
	"connectrpc.com/otelconnect"
	"go.uber.org/automaxprocs/maxprocs"
	"golang.org/x/net/http2"
	"golang.org/x/net/http2/h2c"

	// database driver
	_ "github.com/mattn/go-sqlite3"

	"authors/internal/server/instrumentation/metric"
	"authors/internal/server/litefs"
	"authors/internal/server/litestream"
)

//go:generate sqlc-connect -m authors -migration-path sql/migrations -litefs -litestream -append

const (
	serviceName    = "authors"
	forwardTimeout = 10 * time.Second
)

var (
	dbURL                string
	port, prometheusPort int
	replicationURL       string

	litefsConfig litefs.Config
	liteFS       *litefs.LiteFS
)

func main() {
	var dev bool
	flag.StringVar(&dbURL, "db", "", "The Database connection URL")
	flag.IntVar(&port, "port", 5000, "The server port")
	flag.IntVar(&prometheusPort, "prometheus-port", 0, "The metrics server port")
	flag.BoolVar(&dev, "dev", false, "Set logger to development mode")

	flag.StringVar(&replicationURL, "replication", "", "S3 replication URL")
	litefs.SetFlags(&litefsConfig)
	flag.Parse()

	dbURL = filepath.Join(litefsConfig.MountDir, dbURL)

	initLogger(dev)

	if err := run(); err != nil && !errors.Is(err, http.ErrServerClosed) {
		slog.Error("server error", "error", err)
		os.Exit(1)
	}
}

func run() error {
	_, err := maxprocs.Set()
	if err != nil {
		slog.Warn("startup", "error", err)
	}
	slog.Info("startup", "GOMAXPROCS", runtime.GOMAXPROCS(0))

	db, err := sql.Open("sqlite3", dbURL)
	if err != nil {
		return err
	}
	defer db.Close()

	if replicationURL != "" {
		slog.Info("replication", "url", replicationURL)
		lsdb, err := litestream.Replicate(context.Background(), dbURL, replicationURL)
		if err != nil {
			return fmt.Errorf("init replication error: %w", err)
		}
		defer lsdb.Close()
	}
	if err := ensureSchema(db); err != nil {
		return fmt.Errorf("migration error: %w", err)
	}

	mux := http.NewServeMux()
	var interceptors []connect.Interceptor
	if prometheusPort > 0 {
		observability, err := otelconnect.NewInterceptor()
		if err != nil {
			return err
		}
		interceptors = append(interceptors, observability)
	}
	registerHandlers(mux, db, interceptors)

	var handler http.Handler = mux
	if litefsConfig.MountDir != "" {
		err := litefsConfig.Validate()
		if err != nil {
			return fmt.Errorf("liteFS parameters validation: %w", err)
		}

		liteFS, err = litefs.Start(litefsConfig)
		if err != nil {
			return fmt.Errorf("cannot start LiteFS: %w", err)
		}
		defer liteFS.Close()

		<-liteFS.ReadyCh()
		slog.Info("LiteFS cluster is ready")

		mux.HandleFunc("/nodes/", liteFS.ClusterHandler)
		handler = liteFS.ForwardToLeader(forwardTimeout, "POST", "PUT", "PATCH", "DELETE")(handler)
		handler = liteFS.ConsistentReader(forwardTimeout, "GET")(handler)
	}
	server := &http.Server{
		Addr:    fmt.Sprintf(":%d", port),
		Handler: h2c.NewHandler(handler, &http2.Server{}),
		// Please, configure timeouts!
	}
	if prometheusPort > 0 {
		err := metric.Init(prometheusPort, serviceName)
		if err != nil {
			return err
		}
	}

	done := make(chan os.Signal, 1)
	signal.Notify(done, os.Interrupt, syscall.SIGINT, syscall.SIGTERM)
	go func() {
		sig := <-done
		slog.Warn("signal detected...", "signal", sig)
		ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)
		defer cancel()
		server.Shutdown(ctx)
	}()
	slog.Info("Listening...", "port", port)
	return server.ListenAndServe()
}

func initLogger(dev bool) {
	var handler slog.Handler
	opts := slog.HandlerOptions{
		AddSource: true,
	}
	switch {
	case dev:
		handler = slog.NewTextHandler(os.Stderr, &opts)
	default:
		handler = slog.NewJSONHandler(os.Stderr, &opts)
	}

	logger := slog.New(handler)
	slog.SetDefault(logger)
}
